{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mcudahpc08\u001b[0m  Tue Jun 18 17:41:01 2019\r\n",
      "\u001b[0;36m[0]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[0;31m 41'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m10877\u001b[0m / \u001b[0;33m11178\u001b[0m MB | \u001b[1;30mcarles\u001b[0m(\u001b[0;33m10867M\u001b[0m)\r\n",
      "\u001b[0;36m[1]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[1;31m 74'C\u001b[0m, \u001b[1;32m 87 %\u001b[0m | \u001b[0;36m\u001b[1;33m10879\u001b[0m / \u001b[0;33m11178\u001b[0m MB | \u001b[1;30mcarles\u001b[0m(\u001b[0;33m10869M\u001b[0m)\r\n",
      "\u001b[0;36m[2]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[1;31m 67'C\u001b[0m, \u001b[1;32m 73 %\u001b[0m | \u001b[0;36m\u001b[1;33m10877\u001b[0m / \u001b[0;33m11178\u001b[0m MB | \u001b[1;30mcarles\u001b[0m(\u001b[0;33m10867M\u001b[0m)\r\n",
      "\u001b[0;36m[3]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[1;31m 51'C\u001b[0m, \u001b[0;32m 18 %\u001b[0m | \u001b[0;36m\u001b[1;33m 1239\u001b[0m / \u001b[0;33m11178\u001b[0m MB | \u001b[1;30mcarles\u001b[0m(\u001b[0;33m421M\u001b[0m) \u001b[1;30mcarles\u001b[0m(\u001b[0;33m391M\u001b[0m) \u001b[1;30mcarles\u001b[0m(\u001b[0;33m417M\u001b[0m)\r\n",
      "\u001b[0;36m[4]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[1;31m 75'C\u001b[0m, \u001b[1;32m 98 %\u001b[0m | \u001b[0;36m\u001b[1;33m 3191\u001b[0m / \u001b[0;33m11178\u001b[0m MB | \u001b[1;30mcarles\u001b[0m(\u001b[0;33m3181M\u001b[0m)\r\n",
      "\u001b[0;36m[5]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[0;31m 21'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m   10\u001b[0m / \u001b[0;33m11178\u001b[0m MB |\r\n",
      "\u001b[0;36m[6]\u001b[0m \u001b[0;34mGeForce GTX 1080 Ti\u001b[0m |\u001b[0;31m 22'C\u001b[0m, \u001b[0;32m  0 %\u001b[0m | \u001b[0;36m\u001b[1;33m   10\u001b[0m / \u001b[0;33m11178\u001b[0m MB |\r\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.version_info(major=3, minor=6, micro=7, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "from sep_cons_experiment import SepConsExperiment\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 10, 15, 20, 25]\n",
      "[70, 80, 90]\n"
     ]
    }
   ],
   "source": [
    "widths = list(range(1,5)) + list(range(5,26, 5))\n",
    "depths = list(range(70,91, 10))\n",
    "\n",
    "print(widths)\n",
    "print(depths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2d85fc2e10>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 1, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "WARNING:tensorflow:From /home/carles/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "WARNING:tensorflow:From /home/carles/miniconda3/envs/tf_gpu/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|▎         | 1/27 [03:46<1:38:07, 226.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2d742e7be0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 2, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|▋         | 2/27 [07:16<1:32:17, 221.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bf7f7f0f0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 3, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 3/27 [10:59<1:28:47, 221.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2befbd5978>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 4, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|█▍        | 4/27 [14:46<1:25:36, 223.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bebc66c88>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 5, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▊        | 5/27 [18:46<1:23:43, 228.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2be7891748>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 10, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 6/27 [22:55<1:22:08, 234.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2c4b027a20>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 15, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|██▌       | 7/27 [27:00<1:19:17, 237.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bcaf344e0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 20, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 8/27 [31:07<1:16:06, 240.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bc6bebe10>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 70, 'width': 25, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 9/27 [35:13<1:12:36, 242.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bc37bfef0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 1, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|███▋      | 10/27 [40:02<1:12:36, 256.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bbe4c5160>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 2, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 11/27 [44:54<1:11:12, 267.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bc2eb5588>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 3, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 12/27 [50:10<1:10:26, 281.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bb50226a0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 4, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 13/27 [55:36<1:08:50, 295.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bae920e48>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 5, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 14/27 [1:00:51<1:05:10, 300.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2bab9e5550>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 10, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▌    | 15/27 [1:06:07<1:01:04, 305.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2ba50cdda0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 15, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 16/27 [1:11:42<57:38, 314.43s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b99b3e7f0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 20, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████▎   | 17/27 [1:17:51<55:07, 330.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b994288d0>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 80, 'width': 25, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 18/27 [1:24:32<52:45, 351.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b82cd9f60>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 1, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 19/27 [1:32:19<51:30, 386.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b7b8424a8>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 2, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████▍  | 20/27 [1:39:58<47:37, 408.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2ba0dc3e10>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 3, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 21/27 [1:47:51<42:46, 427.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b73704e10>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 4, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 22/27 [1:55:53<36:59, 443.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b6bdf1240>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 5, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████▌ | 23/27 [2:04:29<31:02, 465.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b644a5a20>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 10, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 24/27 [2:12:45<23:43, 474.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b7e21de80>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 15, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|█████████▎| 25/27 [2:20:55<15:58, 479.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b49c3dd68>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 20, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████▋| 26/27 [2:29:02<08:01, 481.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moons-grid-relu\n",
      "{'self': <toy.Toy object at 0x7f2b42994e10>, 'name': 'moons-grid-relu', 'dataset': 'moons', 'lr': 0.01, 'batch_size': 85, 'epochs': 5000, 'optimizer': 'adam', 'histogram_freq': 0, 'write_grads': False, 'loss': 'crossentropy', 'epoch_start': 0, 'epoch_freq': 0, 'show_on_train': False, 'seed': 10, 'show_input_layer': False, 'show_local_layers': False, 'show_decision_layers': True, 'batch_freq': 0, 'check_weights': False, 'check_gradients': False, 'check_units': None, 'check_optimizer': False, 'write_graph': False, 'check_numerics': False, 'verbose': 0, 'memory': 0.25, 'write_images': False, 'embeddings_freq': None, 'embeddings_layer_names': None, 'extra': None, 'save_config': True, 'store_img': False, 'lr_schedule': None, 'min_lr': 1e-05, 'max_lr': 0.01, 'min_mtm': 0.85, 'max_mtm': 0.95, 'step_size': 1000, 'plot_matrix': False, 'plot_activations': False, 'plot_all_losses': False, 'log_dir': 'moons_grid_summaries', 'cached': False, 'plot_surface': False, 'single_plot': False, 'annealing_dropout_epochs': None, 'annealing_dropout_rate': 0.5, 'print_weights': False, 'kwargs': {'depth': 90, 'width': 25, 'activation': 'relu', 'kernel_size': None, 'layer_parameters': {'padding': 'same', 'use_bias': True}}}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n",
      "{'padding': 'same', 'use_bias': True, 'activation': 'relu'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [2:39:36<00:00, 527.19s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 5000\n",
    "\n",
    "param_grid = ParameterGrid({'activation': ['relu'], 'lr': [0.01], 'batch_size': [85,],\n",
    "                           'depth': depths, 'width': widths,\n",
    "                           })\n",
    "\n",
    "for params in tqdm(param_grid):\n",
    "    activation, lr, batch_size = params['activation'], params['lr'], params['batch_size']\n",
    "    depth, width = params['depth'], params['width']\n",
    "    summary_path = 'moons_grid_summaries'\n",
    "    name = f'moons-grid-{activation}'\n",
    "    print(name)\n",
    "    exp = SepConsExperiment\n",
    "\n",
    "    exp.run(name=name, dataset='moons', epochs=epochs,\n",
    "            optimizer='adam', lr=lr, batch_size=batch_size,\n",
    "            depth=depth, width=width, activation=activation,  seed=10,\n",
    "            kernel_size=None,\n",
    "            memory=0.25,\n",
    "            layer_parameters={\n",
    "                'padding': 'same',                \n",
    "                'use_bias': True,\n",
    "            },\n",
    "            log_dir=summary_path\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras]",
   "language": "python",
   "name": "conda-env-keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
